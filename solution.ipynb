{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f114e5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Credit risk assessment is all about predicting whether someone will default on a loan, which helps banks and lenders make smarter decisions. In practice, the data used for these predictions is often messy—missing values are common, and ignoring them can lead to unreliable results. Imputation techniques fill in these gaps, making sure models have the complete information they need.\n",
    "\n",
    "This project explores how different ways of handling missing data—using the median, linear regression, and non-linear regression—affect the accuracy of credit default predictions. By testing these methods on the UCI Credit Card Default Clients dataset, the goal is to see which approach gives the best results and why thoughtful data preparation matters in real-world credit risk modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a8a85",
   "metadata": {},
   "source": [
    "\n",
    "To kick off the analysis, the credit card default dataset is loaded and a small portion of values in key numerical columns are randomly set to missing. This simulates the kind of incomplete data often found in real-world credit risk problems and sets up a realistic challenge for testing different imputation methods. The target for prediction is whether a client defaulted on their payment next month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dd8d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4d9eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE          0.05\n",
      "BILL_AMT1    0.05\n",
      "BILL_AMT2    0.05\n",
      "dtype: float64\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1    20000.0    2          2         1  24.0      2      2     -1     -1   \n",
      "1   2   120000.0    2          2         2  26.0     -1      2      0      0   \n",
      "2   3    90000.0    2          2         2  34.0      0      0      0      0   \n",
      "3   4    50000.0    2          2         1  37.0      0      0      0      0   \n",
      "4   5    50000.0    1          2         1  57.0     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
      "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
      "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
      "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
      "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
      "0       0.0       0.0       0.0                           1  \n",
      "1    1000.0       0.0    2000.0                           1  \n",
      "2    1000.0    1000.0    5000.0                           0  \n",
      "3    1100.0    1069.0    1000.0                           0  \n",
      "4    9000.0     689.0     679.0                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('UCI_credit_card.csv')\n",
    "\n",
    "# Define numerical columns for missing value injection\n",
    "columns_to_inject = ['AGE', 'BILL_AMT1', 'BILL_AMT2'] \n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Introduce 5% missing (MAR) values per selected column\n",
    "missing_frac = 0.05\n",
    "for col in columns_to_inject:\n",
    "    n_missing = int(missing_frac * len(df))\n",
    "    missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "    df.loc[missing_indices, col] = np.nan\n",
    "\n",
    "# Quick check: Display percent missing per column\n",
    "print(df[columns_to_inject].isnull().mean())  \n",
    "\n",
    "# Preview dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8f16c",
   "metadata": {},
   "source": [
    "As a starting point, let's fill the missing values with the median of each column.\n",
    "# Why median is preferred over mean for imputation?\n",
    "\n",
    "The median is often preferred over the mean for imputation because it is less sensitive to outliers and better represents the center of skewed data distributions. This helps maintain the integrity of the data, especially when some values are unusually high or low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c305974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                            0\n",
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default.payment.next.month    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19360\\1601574350.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_A[col].fillna(median_value, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19360\\1601574350.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_A[col].fillna(median_value, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19360\\1601574350.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_A[col].fillna(median_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for baseline imputation\n",
    "dataset_A = df.copy()\n",
    "\n",
    "# Fill missing values in each column with the median\n",
    "for col in dataset_A.columns:\n",
    "    if dataset_A[col].isnull().any():\n",
    "        median_value = dataset_A[col].median()\n",
    "        dataset_A[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# Quick check: confirm no missing values remain\n",
    "print(dataset_A.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353bcc9",
   "metadata": {},
   "source": [
    "Next, missing values in one column are predicted using a linear regression model built from the other features. \n",
    "\n",
    "This method assumes the missing values are \"Missing At Random\"—that is, the fact that a value is missing depends only on the observed data, not the missing value itself. This way, we can reasonably estimate what the missing value might have been using the other available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffb31640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19360\\3345613589.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_B[target_col].fillna(dataset_B[target_col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset B as a copy\n",
    "dataset_B = df.copy()\n",
    "\n",
    "# Choose the column to impute\n",
    "target_col = 'AGE'\n",
    "\n",
    "# Use only rows where predictors and target are not missing for training\n",
    "predictors = [col for col in dataset_B.columns if col not in [target_col, 'default payment next month']]\n",
    "train_mask = dataset_B[target_col].notnull() & dataset_B[predictors].notnull().all(axis=1)\n",
    "train_X = dataset_B.loc[train_mask, predictors]\n",
    "train_y = dataset_B.loc[train_mask, target_col]\n",
    "\n",
    "# Fit regression model\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(train_X, train_y)\n",
    "\n",
    "# For prediction, use rows where target is missing but predictors are present\n",
    "pred_mask = dataset_B[target_col].isnull() & dataset_B[predictors].notnull().all(axis=1)\n",
    "pred_X = dataset_B.loc[pred_mask, predictors]\n",
    "\n",
    "# Predict and fill missing values\n",
    "dataset_B.loc[pred_mask, target_col] = linreg.predict(pred_X)\n",
    "\n",
    "# If any missing values remain (because predictors were missing), you can fill those with the median as a fallback\n",
    "dataset_B[target_col].fillna(dataset_B[target_col].median(), inplace=True)\n",
    "\n",
    "# Confirm no missing in the imputed column\n",
    "print(dataset_B[target_col].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7548608",
   "metadata": {},
   "source": [
    "Now, let's go to a non-linear regression based imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ccee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_19360\\444263398.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset_C[target_col].fillna(dataset_C[target_col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Copy original data for non-linear imputation\n",
    "dataset_C = df.copy()\n",
    "\n",
    "target_col = 'AGE'\n",
    "predictors = [col for col in dataset_C.columns if col not in [target_col, 'default payment next month']]\n",
    "\n",
    "# Only use rows where predictors and target are not missing for training\n",
    "train_mask = dataset_C[target_col].notnull() & dataset_C[predictors].notnull().all(axis=1)\n",
    "train_X = dataset_C.loc[train_mask, predictors]\n",
    "train_y = dataset_C.loc[train_mask, target_col]\n",
    "\n",
    "# Initialize and fit non-linear regression model\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# Rows where the target is missing and predictors are present\n",
    "pred_mask = dataset_C[target_col].isnull() & dataset_C[predictors].notnull().all(axis=1)\n",
    "pred_X = dataset_C.loc[pred_mask, predictors]\n",
    "\n",
    "# Predict and fill missing values\n",
    "dataset_C.loc[pred_mask, target_col] = knn.predict(pred_X)\n",
    "# dataset_C.loc[pred_mask, target_col] = dtree.predict(pred_X)  # Alternative\n",
    "\n",
    "# Fill any remaining missing values (where predictors were also missing) with the median as fallback\n",
    "dataset_C[target_col].fillna(dataset_C[target_col].median(), inplace=True)\n",
    "\n",
    "# Check missing values are handled\n",
    "print(dataset_C[target_col].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb21831",
   "metadata": {},
   "source": [
    "\n",
    "With the missing values handled in different ways, it’s time to split each dataset into training and testing sets. This step sets the stage for fair model evaluation, and also introduces a fourth approach—listwise deletion—where only fully complete rows are kept for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f57eaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure column names are stripped of extra spaces\n",
    "df.columns = df.columns.str.strip()\n",
    "dataset_A.columns = dataset_A.columns.str.strip()\n",
    "dataset_B.columns = dataset_B.columns.str.strip()\n",
    "dataset_C.columns = dataset_C.columns.str.strip()\n",
    "\n",
    "target = 'default.payment.next.month'\n",
    "\n",
    "# Split imputed datasets (A, B, C)\n",
    "splits = {}\n",
    "for name, data in zip(['A', 'B', 'C'], [dataset_A, dataset_B, dataset_C]):\n",
    "    X = data.drop(columns=[target])\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    splits[name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Dataset D: listwise deletion (drop all rows with missing values)\n",
    "dataset_D = df.dropna()\n",
    "X_D = dataset_D.drop(columns=[target])\n",
    "y_D = dataset_D[target]\n",
    "X_D_train, X_D_test, y_D_train, y_D_test = train_test_split(\n",
    "    X_D, y_D, test_size=0.2, random_state=42, stratify=y_D\n",
    ")\n",
    "splits['D'] = (X_D_train, X_D_test, y_D_train, y_D_test)\n",
    "\n",
    "# Now splits['A'], splits['B'], splits['C'], splits['D'] contain train/test sets for all four datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01dd75",
   "metadata": {},
   "source": [
    "Before training the classifier, each dataset’s features are standardized so they share the same scale. This step ensures that all variables contribute equally to the model and helps improve the reliability of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d081db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize features for each dataset split\n",
    "for name in ['A', 'B', 'C', 'D']:\n",
    "    X_train, X_test, y_train, y_test = splits[name]\n",
    "    \n",
    "    # Fit scaler on training features and transform both train and test\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Replace original splits with scaled versions\n",
    "    splits[name] = (X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "# Now splits contain standardized feature arrays ready for model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac8dbe",
   "metadata": {},
   "source": [
    "With the data ready, it’s time to put each imputation strategy to the test. By training a logistic regression classifier and comparing accuracy, precision, recall, and F1-score across all four datasets, we’ll see how each approach impacts real-world prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8890391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for Dataset A: {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Classification Report for Dataset A:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8175    0.9692    0.8869      4673\n",
      "           1     0.6870    0.2381    0.3537      1327\n",
      "\n",
      "    accuracy                         0.8075      6000\n",
      "   macro avg     0.7522    0.6037    0.6203      6000\n",
      "weighted avg     0.7886    0.8075    0.7690      6000\n",
      "\n",
      "\n",
      "Best parameters for Dataset B: {'C': 100, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Classification Report for Dataset B:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8184    0.9695    0.8875      4192\n",
      "           1     0.6960    0.2452    0.3626      1195\n",
      "\n",
      "    accuracy                         0.8088      5387\n",
      "   macro avg     0.7572    0.6073    0.6251      5387\n",
      "weighted avg     0.7912    0.8088    0.7711      5387\n",
      "\n",
      "\n",
      "Best parameters for Dataset C: {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Classification Report for Dataset C:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.9695    0.8874      4192\n",
      "           1     0.6952    0.2444    0.3616      1195\n",
      "\n",
      "    accuracy                         0.8086      5387\n",
      "   macro avg     0.7567    0.6069    0.6245      5387\n",
      "weighted avg     0.7909    0.8086    0.7708      5387\n",
      "\n",
      "\n",
      "Best parameters for Dataset D: {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Classification Report for Dataset D:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8205    0.9746    0.8909      4010\n",
      "           1     0.7337    0.2474    0.3700      1136\n",
      "\n",
      "    accuracy                         0.8140      5146\n",
      "   macro avg     0.7771    0.6110    0.6304      5146\n",
      "weighted avg     0.8013    0.8140    0.7759      5146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "for name in ['A', 'B', 'C', 'D']:\n",
    "    X_train, X_test, y_train, y_test = splits[name]\n",
    "    \n",
    "    # Remove any rows with NaNs in features for both train and test sets\n",
    "    train_mask = ~np.isnan(X_train).any(axis=1)\n",
    "    test_mask = ~np.isnan(X_test).any(axis=1)\n",
    "    X_train_clean = X_train[train_mask]\n",
    "    y_train_clean = y_train.iloc[train_mask]\n",
    "    X_test_clean = X_test[test_mask]\n",
    "    y_test_clean = y_test.iloc[test_mask]\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        LogisticRegression(random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train_clean, y_train_clean)\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_clean)\n",
    "    print(f\"\\nBest parameters for Dataset {name}: {grid.best_params_}\")\n",
    "    print(f\"Classification Report for Dataset {name}:\\n\")\n",
    "    print(classification_report(y_test_clean, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab32764",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "The results show that all four imputation strategies yield similar overall accuracy (around 81%), but there are important differences in how well each model identifies defaulters (class 1) versus non-defaulters (class 0).\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- **Accuracy** is high for all models (about 81%), but this is mostly driven by the large number of correctly predicted non-defaulters (class 0), which dominate the dataset.\n",
    "- **Precision for class 1 (defaulters)** is moderate (about 0.69–0.73), meaning when the model predicts a default, it is correct about 69–74% of the time.\n",
    "- **Recall for class 1** is low (about 0.24), indicating the model misses most actual defaulters. This is typical in imbalanced datasets, where the minority class is harder to detect.\n",
    "- **F1-score for class 1** is also low (about 0.35–0.37), reflecting the trade-off between precision and recall for defaulters.\n",
    "- **Macro and weighted averages** are higher for precision than recall, again showing the model is better at avoiding false positives than at catching all true positives.\n",
    "\n",
    "### Imputation Strategy Comparison\n",
    "\n",
    "- **Median Imputation (A)**, **Linear Regression (B)**, and **Non-Linear Regression (C)** all perform similarly, with only slight differences in precision and recall for defaulters.\n",
    "- **Listwise Deletion (D)** has the highest precision for defaulters (0.73) and slightly better overall accuracy (0.814), but recall remains low, meaning many defaulters are still missed.\n",
    "- The best hyperparameters vary slightly, but all models favor strong regularization (C=1, 10, or 100) and the 'saga' solver.\n",
    "\n",
    "\n",
    "- All models are good at identifying non-defaulters but struggle to catch actual defaulters, which is a common challenge in credit risk modeling with imbalanced data.\n",
    "- Imputation method does not dramatically change the outcome, but listwise deletion slightly improves precision for defaulters, possibly by removing ambiguous cases.\n",
    "- For practical use, improving recall for defaulters (class 1) would be important—potentially by using resampling techniques, adjusting class weights, or exploring alternative models.\n",
    "\n",
    "### Comment\n",
    "\n",
    "These results highlight the importance of looking beyond accuracy in imbalanced classification problems. Precision, recall, and F1-score for the minority class (defaulters) provide a clearer picture of model effectiveness, and suggest that further work is needed to improve detection of risky clients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26bfef",
   "metadata": {},
   "source": [
    "# Comparitive analysis\n",
    "\n",
    "| Model      | Accuracy | Precision (1) | Recall (1) | F1-score (1) | Macro F1 | Weighted F1 |\n",
    "|------------|----------|---------------|------------|-------------|----------|-------------|\n",
    "| Median     | 0.8075   | 0.6870        | 0.2381     | 0.3537      | 0.6203   | 0.7690      |\n",
    "| Linear     | 0.8088   | 0.6960        | 0.2452     | 0.3626      | 0.6251   | 0.7711      |\n",
    "| Non-Linear | 0.8086   | 0.6952        | 0.2444     | 0.3616      | 0.6245   | 0.7708      |\n",
    "| Listwise   | 0.8140   | 0.7337        | 0.2474     | 0.3700      | 0.6304   | 0.7759      |\n",
    "\n",
    "- **Listwise Deletion (D)** has the highest precision and F1-score for defaulters, but all models struggle with recall for class 1.\n",
    "- **Median, Linear, and Non-Linear Imputation** perform similarly, with only minor differences in metrics.\n",
    "- The overall accuracy is high, but the F1-score for defaulters is low, highlighting the challenge of imbalanced data in credit risk modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83da3f",
   "metadata": {},
   "source": [
    "Listwise Deletion (Model D) and Imputation (Models A, B, C) represent two fundamentally different approaches to handling missing data, each with its own trade-offs.\n",
    "\n",
    "### Listwise Deletion (Model D)\n",
    "- **Pros:**  \n",
    "  - Simple and universally applicable; ensures all data used for modeling is complete.\n",
    "  - If data is Missing Completely at Random (MCAR), estimates are unbiased.\n",
    "- **Cons:**  \n",
    "  - Discards any row with missing values, which can lead to a substantial reduction in sample size and loss of information.\n",
    "  - If missingness is not MCAR (e.g., MAR or MNAR), this can introduce bias and reduce the diversity of the data, making the model less generalizable.\n",
    "  - Larger standard errors and less statistical power due to smaller sample size.\n",
    "\n",
    "### Imputation (Models A, B, C)\n",
    "- **Pros:**  \n",
    "  - Preserves sample size by filling in missing values, allowing the model to leverage all available data.\n",
    "  - Can reduce bias and improve model robustness, especially when missingness is MAR and imputation is done appropriately.\n",
    "- **Cons:**  \n",
    "  - Imputed values are estimates, not true observations, which can introduce their own bias if the imputation model is misspecified.\n",
    "  - Simple imputation methods (mean/median) may not capture the true variability or relationships in the data.\n",
    "  - More complex imputation (regression, non-linear) can improve accuracy but may still struggle if missingness is MNAR.\n",
    "\n",
    "### Why Might Model D Perform Poorly?\n",
    "- **Loss of Data:** By removing all incomplete cases, Model D may lose valuable information, especially if missingness is related to important features or outcomes.\n",
    "- **Bias:** If the missing data is not MCAR, listwise deletion can bias the model by excluding non-random subsets of the data.\n",
    "- **Reduced Power:** Smaller sample size means less power to detect true effects, leading to less reliable predictions.\n",
    "- **Imputation Models May Perform Worse:** If imputation is poorly specified or the missingness mechanism is complex, imputed models can introduce their own errors. However, they generally retain more information and diversity, which can help the model generalize better, especially in real-world scenarios where missingness is rarely MCAR.\n",
    "\n",
    "### Summary\n",
    "- **Listwise Deletion** is simple but risky unless missingness is truly random; it can lead to bias and reduced model performance due to loss of data.\n",
    "- **Imputation** methods, while imperfect, usually offer better use of available data and can improve model robustness, especially when missingness is related to observed variables (MAR).[3][6]\n",
    "- The best approach depends on the nature of the missing data and the modeling context, but in most practical cases, imputation is preferred over listwise deletion for maintaining data integrity and predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54f9f6",
   "metadata": {},
   "source": [
    "# Which regression method performed better?\n",
    "Linear and non-linear regression imputation performed almost identically in your results. This suggests the relationship between the imputed feature and its predictors is mostly linear, so the extra flexibility of non-linear methods did not provide an advantage. If the relationship were more complex, non-linear methods could outperform linear imputation. In your case, linear regression was sufficient because the predictors and the imputed feature were linearly related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fe778",
   "metadata": {},
   "source": [
    "# Conclusion and Recommendation\n",
    "\n",
    "The best strategy for handling missing data in this scenario is **imputation using regression-based methods (linear or non-linear)** rather than listwise deletion.\n",
    "\n",
    "### Justification\n",
    "\n",
    "- **Classification Performance:**  \n",
    "  All imputation models (A, B, C) achieved similar accuracy and F1-scores, but listwise deletion (Model D) only slightly outperformed them in precision and F1-score for defaulters. However, this came at the cost of discarding a significant portion of the data, which can reduce model generalizability and statistical power.\n",
    "\n",
    "- **Conceptual Implications:**  \n",
    "  Imputation preserves the full dataset, allowing the model to learn from more examples and maintain diversity. Listwise deletion risks bias and loss of information, especially if missingness is not completely random. Regression imputation is robust when the relationship between features is linear or moderately complex, as in your results, and avoids the pitfalls of both simple imputation and data loss.\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "**Use regression-based imputation (linear or non-linear) for missing data.**  \n",
    "This approach balances strong classification performance with conceptual soundness, retaining more data and reducing bias compared to listwise deletion. It is especially effective when the relationship between features is not highly non-linear, as shown by the similar results for both regression methods in your analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
